{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc78c1b-8cd7-49e9-94fc-d3b291e57b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OPENAI_API_KEY: sk-proj-cA ...\n"
     ]
    }
   ],
   "source": [
    "# --- 環境設定 ---\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # .envの読み込み\n",
    "\n",
    "# 動作確認\n",
    "print(\"✅ OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\")[:10], \"...\")  # 先頭10文字だけ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc43179-5df9-43c1-a166-52426ea5bfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'こんにちは！LangChainの練習を始めるのは素晴らしいアイデアですね。LangChainは、言語モデルを使ったアプリケーションを構築するための強力なフレームワークです。どのようなことに興味がありますか？具体的なプロジェクトや機能について知りたいことがあれば教えてください。基本的な使い方やサンプルコードを提供することもできますよ。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "response = llm.invoke(\"こんにちは！LangChainの練習を始めたいです。\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e61bff9c-9bb6-46c7-b6bb-f4fbb80de1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"空の色は？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec2cc21c-6fd4-4859-ae1c-de1fa8e6a965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "空の色は、通常は青いとされています。これは、太陽の光が大気中の粒子に散乱されるためです。晴れた日には、空が明るい青色に見えますが、日の出や日の入りの時にはオレンジや赤、紫などの色が混ざることもあります。また、曇りの日や雨の日にはグレーっぽく見えることもあります。空の色は、時間や天候によって変化します。\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a98d98bb-eb6a-4d29-8c56-272f168c5d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パリ\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = [HumanMessage(\"フランスの首都は？\")]\n",
    "\n",
    "print(model.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96d97cb7-4b47-419c-80b7-1f530d590c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パリです！！！\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "system_msg = SystemMessage(\n",
    "    '''あなたは優秀なアシスタントです。質問に対して3つの感嘆符を付けて回答してください。'''\n",
    ")\n",
    "human_msg = HumanMessage('フランスの首都は？')\n",
    "print(model.invoke([system_msg, human_msg]).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edc975f2-c114-4903-989a-e9208775e008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"以下のコンテキストに基づいて質問に答えてください。提供された情報で答えられない場合は「I don't know」と答えてください。\\n\\nコンテキスト: NLPの最新の進歩は大型言語モデル（LLM）によって牽引されています。これらのモデルはより小規模なモデルより高い性能を発揮し、NLP機能を備えたアプリケーションを開発する開発者にとって不可欠な存在となっています。開発者はHugging Faceの`transformers`ライブラリを通じてこれらのモデルを利用したり、OpenAIとCohereが提供する`openai`や`cohere`ライブラリを利用したりできます。\\n\\n質問: どのモデルプロバイダーがLLMを提供していますか？\\n\\n回答:\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"\"\"以下のコンテキストに基づいて質問に答えてください。提供された情報で答えられない場合は「I don't know」と答えてください。\n",
    "\n",
    "コンテキスト: NLPの最新の進歩は大型言語モデル（LLM）によって牽引されています。これらのモデルはより小規模なモデルより高い性能を発揮し、NLP機能を備えたアプリケーションを開発する開発者にとって不可欠な存在となっています。開発者はHugging Faceの`transformers`ライブラリを通じてこれらのモデルを利用したり、OpenAIとCohereが提供する`openai`や`cohere`ライブラリを利用したりできます。\n",
    "\n",
    "質問: どのモデルプロバイダーがLLMを提供していますか？\n",
    "\n",
    "回答:\"\"\")\n",
    "template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large\n",
    "        Language Models (LLMs). These models outperform their smaller\n",
    "        counterparts and have become invaluable for developers who are creating\n",
    "        applications with NLP capabilities. Developers can tap into these\n",
    "        models through Hugging Face's `transformers` library, or by utilizing\n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere`\n",
    "        libraries, respectively.\"\"\",\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f1b1f8c-6bd5-489d-beb2-ae8f27830d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI and Cohere\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# `template`と`model`は何度も再利用できる\n",
    "template = PromptTemplate.from_template(\"\"\"Answer the question based on the\n",
    "    context below. If the question cannot be answered using the information\n",
    "    provided, answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\")\n",
    "\n",
    "model = OpenAI()\n",
    "\n",
    "# `prompt`と`completion`は、`template`と`model`を一度使用した結果である\n",
    "prompt = template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large\n",
    "        Language Models (LLMs). These models outperform their smaller\n",
    "        counterparts and have become invaluable for developers who are creating\n",
    "        applications with NLP capabilities. Developers can tap into these\n",
    "        models through Hugging Face's `transformers` library, or by utilizing\n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere`\n",
    "        libraries, respectively.\"\"\",\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "})\n",
    "\n",
    "completion = model.invoke(prompt)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83f529e2-e0de-4588-bb2f-358b202d23a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAIとCohereの「openai」ライブラリと「cohere」ライブラリがLLM（Large Language Model）を提供しています。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''以下の文脈に基づいて質問に答えてください。 提供された情報で質問に答えられない場合は、「わかりません」と答えてください。'''),\n",
    "    ('human', 'Context: {context}'),\n",
    "    ('human', 'Question: {question}'),\n",
    "])\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "prompt = template.invoke({\n",
    "    \"context\": \"\"\"NLPにおける最新の進歩は、大規模言語モデル（LLM）によって推進されています。これらのモデルは、小規模なモデルよりも優れた性能を発揮し、NLP機能を備えたアプリケーションを開発する開発者にとって非常に貴重なものとなっています。開発者は、Hugging Faceの「transformers」ライブラリ、またはOpenAIとCohereの「openai」ライブラリと「cohere」ライブラリを通じて、これらのモデルを利用できます。\"\"\",\n",
    "    \"question\": \"どのモデルプロバイダーが LLM を提供していますか?\"\n",
    "})\n",
    "\n",
    "completion = model.invoke(prompt)\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03801e97-06e6-4518-a6bc-5e0796079289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerWithJustification(answer='どちらも同じ重さです。', justification='レンガ1ポンドと羽毛1ポンドは、どちらも1ポンドという同じ単位で測定されているため、重さは等しいです。ポンドは質量の単位であり、物質の種類に関わらず、同じ数値のポンドは同じ重さを示します。')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    '''ユーザーの質問への回答と、その回答の正当性（根拠）を含むデータモデル'''\n",
    "    answer: str\n",
    "    '''ユーザーの質問への回答'''\n",
    "    justification: str\n",
    "    '''回答の正当性を示す根拠'''\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustification)\n",
    "structured_llm.invoke(\"レンガ１ポンドと羽毛１ポンドではどちらが重いですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ba76afa-817c-4fce-9f67-a1eeef76083d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'cherry']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "items = parser.invoke(\"apple, banana, cherry\")\n",
    "print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1366bdee-4193-4ad6-988e-b85feaac9f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "completion = model.invoke('Hi there!')\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5efc8556-2a92-4b61-9ece-d31f0375c407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUTdj2dllFI1R0Eu0D4fFlhq8U1w7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--ae3c8140-f028-4f65-a203-dc0413e6f150-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Goodbye! Have a great day!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 10, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUTdjlf5WcNknTQtIVsLf2alomGCa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--603a16fc-00f3-4927-8614-edb20dca5a43-0', usage_metadata={'input_tokens': 10, 'output_tokens': 8, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "completion = model.batch(['Hi! there!', 'Bye!'])\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e082610e-4e72-43fd-a837-c65725acc744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good\n",
      "bye\n",
      "!\n",
      " Have\n",
      " a\n",
      " great\n",
      " day\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in model.stream('Bye!'):\n",
    "    print(token.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e08f9420-1809-4d63-966f-0e5447dc89b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLM（Large Language Model）を提供しているいくつかのモデルプロバイダーがありますが、最も有名なのはOpenAIのGPTシリーズです。そのうちの一つであるGPT-3は、最も広く知られている大規模言語モデルの一つです。その他のプロバイダーには、GoogleのBERT、FacebookのRoBERTaなどがあります。これらのモデルは、様々な言語タスクで高い性能を発揮しています。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 154, 'prompt_tokens': 49, 'total_tokens': 203, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUTima4Evd6CpKdonV4BITHJ6CCTz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a643f3c5-4dbb-4063-8a97-ae1d38095418-0', usage_metadata={'input_tokens': 49, 'output_tokens': 154, 'total_tokens': 203, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'あなたは頼もしいアシスタントです。'),\n",
    "    ('human', '{question}'),\n",
    "])\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    return model.invoke(prompt)\n",
    "\n",
    "chatbot.invoke({\"question\": \"どのモデルプロバイダーが LLM を提供していますか?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "651c429e-f563-471a-b0f7-c09e62d25d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Several\n",
      " universities\n",
      " and\n",
      " law\n",
      " schools\n",
      " around\n",
      " the\n",
      " world\n",
      " offer\n",
      " Master\n",
      " of\n",
      " Laws\n",
      " (\n",
      "LL\n",
      "M\n",
      ")\n",
      " programs\n",
      ".\n",
      " Some\n",
      " well\n",
      "-known\n",
      " institutions\n",
      " that\n",
      " offer\n",
      " L\n",
      "LM\n",
      " programs\n",
      " include\n",
      ":\n",
      "\n",
      "\n",
      "1\n",
      ".\n",
      " Harvard\n",
      " Law\n",
      " School\n",
      "\n",
      "\n",
      "2\n",
      ".\n",
      " University\n",
      " of\n",
      " Cambridge\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      " Yale\n",
      " Law\n",
      " School\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      " Oxford\n",
      " University\n",
      "\n",
      "\n",
      "5\n",
      ".\n",
      " Stanford\n",
      " Law\n",
      " School\n",
      "\n",
      "\n",
      "6\n",
      ".\n",
      " New\n",
      " York\n",
      " University\n",
      " School\n",
      " of\n",
      " Law\n",
      "\n",
      "\n",
      "7\n",
      ".\n",
      " London\n",
      " School\n",
      " of\n",
      " Economics\n",
      " and\n",
      " Political\n",
      " Science\n",
      " (\n",
      "L\n",
      "SE\n",
      ")\n",
      "\n",
      "8\n",
      ".\n",
      " University\n",
      " of\n",
      " California\n",
      ",\n",
      " Berkeley\n",
      " School\n",
      " of\n",
      " Law\n",
      "\n",
      "\n",
      "9\n",
      ".\n",
      " Georgetown\n",
      " University\n",
      " Law\n",
      " Center\n",
      "\n",
      "\n",
      "10\n",
      ".\n",
      " University\n",
      " of\n",
      " Melbourne\n",
      " Law\n",
      " School\n",
      "\n",
      "\n",
      "\n",
      "These\n",
      " are\n",
      " just\n",
      " a\n",
      " few\n",
      " examples\n",
      ",\n",
      " and\n",
      " there\n",
      " are\n",
      " many\n",
      " other\n",
      " institutions\n",
      " that\n",
      " offer\n",
      " L\n",
      "LM\n",
      " programs\n",
      " as\n",
      " well\n",
      ".\n",
      " It\n",
      " is\n",
      " recommended\n",
      " to\n",
      " research\n",
      " the\n",
      " specific\n",
      " program\n",
      " offerings\n",
      ",\n",
      " requirements\n",
      ",\n",
      " and\n",
      " areas\n",
      " of\n",
      " specialization\n",
      " offered\n",
      " by\n",
      " each\n",
      " institution\n",
      " before\n",
      " applying\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    for token in model.stream(prompt):\n",
    "        yield token\n",
    "\n",
    "for part in chatbot.stream({\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "}):\n",
    "    print(part.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d90be60c-6976-456e-b89d-f5a1a0a265c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLM（Large Language Models）を提供しているモデルプロバイダーの一例として、OpenAIやGoogleがあります。これらのプロバイダーは大規模な言語モデルを開発し、研究者や開発者に提供しています。また、MicrosoftやFacebookもまた、大規模な言語モデルの研究を行っており、将来的にLLMの提供を行う可能性があります。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 49, 'total_tokens': 181, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUU2QhNZrM4bKefeIGs5dRmCzQbFv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--96e2ff72-dede-44b8-916f-05fb130958e8-0', usage_metadata={'input_tokens': 49, 'output_tokens': 132, 'total_tokens': 181, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@chain\n",
    "async def chatbot(values):\n",
    "    prompt = await template.ainvoke(values)\n",
    "    return await model.ainvoke(prompt)\n",
    "\n",
    "await chatbot.ainvoke({\"question\": \"どのモデルプロバイダーが LLM を提供していますか?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538fe826-fbe2-44b6-bbde-76361e166e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
